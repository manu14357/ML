"""Initial migration

Revision ID: 0dcdb8ac82a8
Revises: 
Create Date: 2025-06-26 23:38:03.238814

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy import Text
# revision identifiers, used by Alembic.
revision = '0dcdb8ac82a8'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('datasets',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('filename', sa.String(length=255), nullable=False),
    sa.Column('original_filename', sa.String(length=255), nullable=False),
    sa.Column('file_path', sa.String(length=500), nullable=False),
    sa.Column('file_size', sa.BigInteger(), nullable=True),
    sa.Column('file_type', sa.String(length=50), nullable=True),
    sa.Column('mime_type', sa.String(length=100), nullable=True),
    sa.Column('rows_count', sa.Integer(), nullable=True),
    sa.Column('columns_count', sa.Integer(), nullable=True),
    sa.Column('memory_usage', sa.BigInteger(), nullable=True),
    sa.Column('missing_values_count', sa.Integer(), nullable=True),
    sa.Column('duplicate_rows_count', sa.Integer(), nullable=True),
    sa.Column('data_quality_score', sa.Float(), nullable=True),
    sa.Column('columns_info', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('data_types', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('sample_data', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('statistics', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('eda_generated', sa.Boolean(), nullable=True),
    sa.Column('eda_results', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('eda_charts', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('processing_log', sa.Text(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('last_accessed', sa.DateTime(), nullable=True),
    sa.Column('tags', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('category', sa.String(length=100), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('system_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('level', sa.String(length=20), nullable=False),
    sa.Column('message', sa.Text(), nullable=False),
    sa.Column('category', sa.String(length=100), nullable=True),
    sa.Column('event_type', sa.String(length=100), nullable=True),
    sa.Column('source', sa.String(length=100), nullable=True),
    sa.Column('context_data', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('stack_trace', sa.Text(), nullable=True),
    sa.Column('request_id', sa.String(length=100), nullable=True),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('user_agent', sa.String(length=500), nullable=True),
    sa.Column('execution_time', sa.Float(), nullable=True),
    sa.Column('memory_usage', sa.BigInteger(), nullable=True),
    sa.Column('cpu_usage', sa.Float(), nullable=True),
    sa.Column('timestamp', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('resolved_at', sa.DateTime(), nullable=True),
    sa.Column('resolution_notes', sa.Text(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('system_logs', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_system_logs_timestamp'), ['timestamp'], unique=False)

    op.create_table('workflows',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('workflow_data', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('nodes', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('connections', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('version', sa.String(length=20), nullable=True),
    sa.Column('category', sa.String(length=100), nullable=True),
    sa.Column('tags', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('execution_log', sa.Text(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('execution_results', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('output_datasets', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('output_models', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('execution_time', sa.Float(), nullable=True),
    sa.Column('nodes_executed', sa.Integer(), nullable=True),
    sa.Column('nodes_failed', sa.Integer(), nullable=True),
    sa.Column('is_scheduled', sa.Boolean(), nullable=True),
    sa.Column('schedule_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('last_run', sa.DateTime(), nullable=True),
    sa.Column('next_run', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('last_executed', sa.DateTime(), nullable=True),
    sa.Column('execution_count', sa.Integer(), nullable=True),
    sa.Column('success_count', sa.Integer(), nullable=True),
    sa.Column('failure_count', sa.Integer(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('ml_models',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('algorithm', sa.String(length=100), nullable=False),
    sa.Column('model_type', sa.String(length=50), nullable=False),
    sa.Column('version', sa.String(length=20), nullable=True),
    sa.Column('model_path', sa.String(length=500), nullable=True),
    sa.Column('model_size', sa.BigInteger(), nullable=True),
    sa.Column('dataset_id', sa.Integer(), nullable=True),
    sa.Column('training_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('features', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('target_column', sa.String(length=255), nullable=True),
    sa.Column('training_metrics', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('validation_metrics', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('test_metrics', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('accuracy', sa.Float(), nullable=True),
    sa.Column('precision', sa.Float(), nullable=True),
    sa.Column('recall', sa.Float(), nullable=True),
    sa.Column('f1_score', sa.Float(), nullable=True),
    sa.Column('r2_score', sa.Float(), nullable=True),
    sa.Column('mse', sa.Float(), nullable=True),
    sa.Column('mae', sa.Float(), nullable=True),
    sa.Column('cv_scores', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('cv_mean', sa.Float(), nullable=True),
    sa.Column('cv_std', sa.Float(), nullable=True),
    sa.Column('feature_importance', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('shap_values', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('permutation_importance', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('training_time', sa.Float(), nullable=True),
    sa.Column('training_log', sa.Text(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('is_deployed', sa.Boolean(), nullable=True),
    sa.Column('deployment_url', sa.String(length=500), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('trained_at', sa.DateTime(), nullable=True),
    sa.Column('deployed_at', sa.DateTime(), nullable=True),
    sa.Column('last_used', sa.DateTime(), nullable=True),
    sa.Column('tags', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('category', sa.String(length=100), nullable=True),
    sa.Column('prediction_count', sa.Integer(), nullable=True),
    sa.Column('download_count', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('visualizations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('chart_type', sa.String(length=100), nullable=False),
    sa.Column('chart_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('chart_data', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('dataset_id', sa.Integer(), nullable=True),
    sa.Column('data_query', sa.Text(), nullable=True),
    sa.Column('layout_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('style_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('theme', sa.String(length=50), nullable=True),
    sa.Column('is_dashboard', sa.Boolean(), nullable=True),
    sa.Column('dashboard_layout', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('widgets', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('is_interactive', sa.Boolean(), nullable=True),
    sa.Column('filters', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('drill_down_config', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('export_formats', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('is_public', sa.Boolean(), nullable=True),
    sa.Column('shared_with', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('cache_enabled', sa.Boolean(), nullable=True),
    sa.Column('cache_duration', sa.Integer(), nullable=True),
    sa.Column('last_cached', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('last_viewed', sa.DateTime(), nullable=True),
    sa.Column('view_count', sa.Integer(), nullable=True),
    sa.Column('export_count', sa.Integer(), nullable=True),
    sa.Column('tags', postgresql.JSON(astext_type=Text()), nullable=True),
    sa.Column('category', sa.String(length=100), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('visualizations')
    op.drop_table('ml_models')
    op.drop_table('workflows')
    with op.batch_alter_table('system_logs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_system_logs_timestamp'))

    op.drop_table('system_logs')
    op.drop_table('datasets')
    # ### end Alembic commands ###
